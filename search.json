[
  {
    "objectID": "index.html#what-is-differential-abundance-da-analysis",
    "href": "index.html#what-is-differential-abundance-da-analysis",
    "title": "Differential Abundance anaysis",
    "section": "1. What is Differential Abundance (DA) Analysis?",
    "text": "1. What is Differential Abundance (DA) Analysis?\nDifferential Abundance Analysis (DAA) is the use of various statistical methods to identify significant differences in the abundances of individual taxa between two or more comparison groups.\nMicrobiome data possesses unique characteristics that contribute to the complexity of its analysis.To address these inherent data challenges, different DAA tools and packages operate based on distinct statistical assumptions or computational frameworks. The choice of package is therefore critical, as each is specifically designed to handle certain data features more effectively than others. Some of the data characteristics of a microbiome data includes:\n\na) Compostionality:\nCompositionality is the most important characteristic of microbiome data. The ASV/OTU count, which is the main input used in Differential Abundance (DA) analysis, represents relative abundance; that is, the count is proportional to the total number of sequencing reads (library size) per sample and not the true absolute count for that particular taxon. Consequently, an apparent increase in one taxon’s relative count naturally results in a decrease in the relative abundance of another taxon’s count. This is a significant problem because working solely with relative abundance often does not reflect the true absolute count of the species in our data and can therefore lead to a loss of biological significance..\n\n\nb) Sparisty\nMicrobiome datasets feature a large number of taxa (OTUs/ASVs) compared to the smaller number of samples we work with, which impacts the statistical modeling as there are more features than samples. An important point to note about sparse data is that sometimes the taxon is genuinely not present (a structural zero), hence the count is zero, but sometimes the zero count could also be a technical error in the sequencing and the taxon was simply not detected because it had low abundance (a sampling zero).\n\n\nc) Overdispersion\nIn the count data, the variance of counts for a given taxon is significantly larger than its mean. This characteristic is known as over-dispersion, which violates the assumptions of a simple distribution (like the Poisson distribution) often used in count data.",
    "crumbs": [
      "Differential Abundance anaysis"
    ]
  },
  {
    "objectID": "index.html#what-is-the-analysis-in-nejmans-paper",
    "href": "index.html#what-is-the-analysis-in-nejmans-paper",
    "title": "Differential Abundance anaysis",
    "section": "2. What is the analysis in Nejman’s Paper ,",
    "text": "2. What is the analysis in Nejman’s Paper ,\nThe paper characterized the tumor-associated microbiome across 7 cancer types using the 16s rRNA sequencing and statistical diversity analysis by looking into the community difference through alpha and beta diveristy. They found out that breast cancer had the most diverse microbiome profile\nWhat I am doing in this analysis is re-analyzing the same dataset with four established DA methods - ALDEx2, ANCOM-II , DESeq2 and MaAsLin2. This will help identify taxa that differ significantly between tumor (T) vs Normal adjacent tumor (NAT). This will allow comparision of the DA tools and also study if these packages reproduce the study’s key finding that the breast tumor had the richest and most diverse microbiome profile.\nOur use of multiple differential abundance (DA) tools follows the consensus approach recommended by (Nearing et al., 2022). In their study, the authors systematically evaluated 14 DA methods across 38 microbiome datasets and concluded that, because each method relies on different statistical assumptions, the results can vary substantially. Therefore, they recommended using a consensus strategy examining the overlapping significant features (ASVs) across multiple DA tools to obtain more reliable biological interpretations.n\nBased on these findings, we selected ALDEx2 and ANCOM-II, which were identified as the most conservative and consistent tools, as well as MaAsLin2 and DESeq2. Although DESeq2 was originally designed for RNA-seq data and was reported by Nearing et al. to produce relatively higher false discovery rates (FDR) in microbiome applications, we included it for comparison because (Calgaro et al., 2020) found DESeq2 to be among the top-performing methods overall. Given this contrast in reported performance, including DESeq2 in our analysis allows us to evaluate how it behaves on this dataset relative to the other DA frameworks.",
    "crumbs": [
      "Differential Abundance anaysis"
    ]
  },
  {
    "objectID": "index.html#data-cleaning",
    "href": "index.html#data-cleaning",
    "title": "Differential Abundance anaysis",
    "section": "3.1 Data cleaning",
    "text": "3.1 Data cleaning\n\n3.1.01 Splitting into clincal and prevalence table\nThe first step in our analysis was splitting the table into a prevalence.csv and a clinical.csv file. In the clinical table, we added a new column called Barcodes, which represents the sequencing sample IDs. The Sample_ID (WIS) in the clinical data were numeric, while in the prevalence table, the sample IDs were in a format such as 2015-11-17 - Hiseq-4/BC11_GTATAACA. We matched each barcode with its corresponding WIS Sample ID to ensure proper mapping and alignment between the two tables during the DA step.\n\n\n3.1.02 Removing Bact ID &gt;= 30,000\nIn Table S2, at the bottom of the prevalence table, we had BactID values ≥ 30,000, which did not represent species-level data. The corresponding prevalence values for these rows represented higher taxonomic levels, such as genus or family. Therefore, all rows with BactID ≥ 30,000 were removed from the prevalence table, as they do not reflect species-level abundance and saving the file as prevalence_after_bactID_01.csv\n\n\n3.1.03 Prevalence filtering\nIn this step, we removed species identified as likely contaminants from lab procedures. Low biomass tumor samples are prone to contamination from DNA extraction kits, PCR reagents, paraffin embedding, and other sources. Following the paper’s Filter 1 method, we removed any species that appeared in more than 7.5% of DNA extraction/NTC negative controls or more than 7.5% of paraffin embedding controls. These two values were found in the first two columns of the prevalence table, named “Prevalence in DNA extraction/NTC negative controls” and “Prevalence in Paraf. Controls.” The 7.5% threshold was chosen as the inflection point in the bimodal distribution, where species below this value were considered real detections and those above were likely contaminants. We converted the percentage strings to numeric values and applied an OR rule to remove species that exceeded 7.5% in either control type.\nAfter filtering, we removed 168 contaminant species out of 11,211 (1.5%) and kept 11,043 clean species (98.5%). The resulting table was saved as prevalence_no_contaminants_02.csv, which matches the 168 species reported as removed in Filter 1 of the paper.\n\n\n3.1.04 Format coversion - into relative and integer count\nThe original Table S2 is described as the normalized reads of all samples in the study with clinical data. It also includes two rows named total normalized reads and total normalized reads without general contaminants. These rows summarize the overall read counts per sample but still include taxa with BactID values greater than 30,000, which are higher-level taxa (not species).\nBecause of this, we did not use those total normalized read values directly. Instead, after filtering out all rows with BactID ≥ 30,000, we recalculated the total normalized reads for each sample using the filtered prevalence table. This allowed us to obtain accurate totals that represent only species-level data.\nFrom this recalculated data, we created two separate versions for different DA tools.\nFor the integer count format, we rounded the normalized read values (floats) to the nearest whole number, since count-based tools like DESeq2 require integer inputs.\nFor the relative abundance format, we divided each sample’s read values by its corresponding total normalized reads, producing proportions that sum to approximately 1.0 per sample.\nThis conversion step was necessary because some DA tools operate on count data, while others are designed for compositional or relative abundance data. The files were saved as prevalence_relative_abundance_all_csv and prevalence_integer_counts_all.csv.",
    "crumbs": [
      "Differential Abundance anaysis"
    ]
  },
  {
    "objectID": "index.html#cancer-specific-data-extraction",
    "href": "index.html#cancer-specific-data-extraction",
    "title": "Differential Abundance anaysis",
    "section": "3.2 Cancer specific data extraction",
    "text": "3.2 Cancer specific data extraction\n\n3.2.01 Breast Cancer data\n\nClincal data:\nIn this step, we extracted cancer-specific data for tumor and normal tissue comparisons. We selected three cancer types for the DA analysis: breast, ovary, and lung. The other cancers (melanoma, pancreas, GBM, and bone) were excluded because they lacked normal or NAT samples.\nFor the breast dataset, we first extracted the breast-specific clinical data and saved it as breast_clinical.csv. We then created another file called breast_clinical_aligned.csv, which included the corresponding barcodes for each sample. The barcodes were extracted and matched with the Sample_ID (WIS) values to ensure that each sample in the clinical file correctly aligned with the sample IDs in the prevalence table. The alignment was performed using the Jupyter source file named alignment_breast.ipynb, from which the breast_clinical_aligned.csv file was generated. This files contains all breast cancer sample that is N , NAT and T. This alignment step ensured that the metadata and prevalence data were perfectly matched before performing any downstream analysis.\n\n\nPrevalence data : Applying 3 % prevalence filtering\nNearing et al’s paper also recommneds applying a prevalence filtering of the data before we proceed to do a DA analysis. They tried it with a 10 % filtering , but because our data is a low biomass data , we only proceeded to use a 3% filtering threshold\nIn this step, we performed cancer-specific prevalence filtering using the 3% threshold. From the prevalence table, we used the two files prevalence_relative_abundance_all.csv and prevalence_integer_counts_all.csv.\nFrom each of these, we extracted the breast cancer samples. After extracting the breast data for both relative and integer formats, we applied the 3% prevalence filtering, where a species had to be present in at least 3% of the samples to be kept. Once the filtering was applied, the resulting files were saved as breast_relative_filtered.csv and breast_integers_filtered.csv. This process was done using the Jupyter source file named breast_cancer_RandI.ipynb.\n\n\n\n3.2.01 Creating R file without error and DA ready\nIn this step, we prepared the breast cancer data for differential abundance analysis by creating standardized input files compatible with all DA tools. This was done using the Python script named prepare_DA_input.ipynb.\nFrom the previously filtered breast data, we kept only the Tumor and NAT samples and removed all other tissue types such as Normal and Fibroadenoma. This filtering was necessary because the DA analysis focuses on comparing Tumor vs NAT. We also analyzed possible confounding factors such as DNA extraction batch, sequencing center, and patient pairing, which are summarized in the DA_design_info.txt file.\nTo make the dataset compatible with R, we created a new column called Sample_ID_clean. In the original dataset, sample names contained characters like spaces, dashes, and slashes (for example, 2015-11-17 - Hiseq-4/RDB102_TGCCTCAA), which caused issues when loading the data in R. These were replaced with underscores to create a consistent, R-friendly sample ID format. This cleaned sample ID was used as the main identifier to align the metadata and prevalence matrices.\nThe resulting files included DA_metadata.csv, DA_counts_integer.csv, and DA_counts_relative.csv, along with DA_design_info.txt, which documents the final design formula and any data limitations. These files are the DA-ready versions that were later used in R for differential abundance analysis with tools such as DESeq2, MaAsLin2, ALDEx2, and ANCOM-II.\nIt is important to know that the filtered DA_metadata along with the DA_counts and DA integers contains only NAT vs T samples. Some of the NAT and T samples came from the same patients in the Nejman’s study . We call them as Paired patient which can be added as design in some DA tools so there is no paired Patient bias in the statistical analysis So the DA_metadata has both paired and unpaired NAT and T samples.\n\n\n3.2.02 Confounding factor analysis\nConfounding analysis was performed to identify variables that might bias the observed differences in bacterial abundance between tumor and NAT samples. This step is essential before running differential abundance analysis because certain technical or biological factors (like sequencing batch or center) can artificially influence results. After testing all available covariates using the script ,confounding_BC.ipynb, , we found that some were confounded and therefore excluded from the model. As a result, only Center and Group were used as fixed effects for downstream DA tools, while Patient_ID was included as a random effect in models that support random effects (such as MaAsLin2).",
    "crumbs": [
      "Differential Abundance anaysis"
    ]
  },
  {
    "objectID": "index.html#differential-abundance-analysis",
    "href": "index.html#differential-abundance-analysis",
    "title": "Differential Abundance anaysis",
    "section": "3.3 Differential Abundance Analysis",
    "text": "3.3 Differential Abundance Analysis\n\n3.3.01 DESEq2\nDESeq2 is a count-based tool originally developed for RNA-seq and is adapted for microbiome data. It handles overdispersion in counts, allows for covariate adjustment (such as Center), but cannot handle random effects (e.g., patient pairing).\nDESeq2 uses a negative binomial model for count data:\n\\[\nK_{ij} \\sim NB(\\mu_{ij}, \\alpha_i)\n\\]\nwhere:\n\n\\(K_{ij}\\) is the observed count for feature \\(i\\) in sample \\(j\\)\n\\(\\mu_{ij}\\) is the expected mean\n\\(\\alpha_{i}\\) is the dispersion parameter\n\nThe design formula used was:\n\\[\n\\log(\\mu_{ij}) = \\beta_0 + \\beta_{\\text{Center}} + \\beta_{\\text{Group}}\n\\]\nwhere:\n\n\\(\\beta_0\\) is the intercept\n\n\\(\\beta_{\\text{Center}}\\) accounts for center-specific effects\n\n\\(\\beta_{\\text{Group}}\\) tests the effect of Tumor vs NAT, the main variable of interest\n\nFixed Effects:\nAll variables in the formula (~ Center + Group) are treated as fixed effects. DESeq2 estimates the effect of each variable, for example:\n\nHow does being in NAT vs Tumor affect bacterial abundance ?\nHow does being at Sheba vs Maccabi (center names ) affect abundance?\n\nWhy Patient_ID Was Not Included:\nThere are too many Patient_ID levels (154 paired patients), leading to a “not full rank” error. DESeq2 cannot separate patient and group effects in a perfectly paired or mixed design.\n\nLoad the Data\n\nlibrary(DESeq2)\n\n# Load with check.names=FALSE to preserve sample IDs\nmetadata &lt;- read.csv(\"DA_metadata.csv\", row.names=1, check.names=FALSE)\ncounts_full &lt;- read.csv(\"DA_counts_integer.csv\", check.names=FALSE)\n\n# Separate taxonomy from counts\ntaxonomy_cols &lt;- c(\"Prevalence in DNA extraction/NTC negative controls\",\n                   \"Prevalence in Paraf. Controls\",\n                   \"BactID\", \"domain\", \"phylum\", \"class\", \"order\", \n                   \"family\", \"genus\", \"species\")\n\ntaxonomy &lt;- counts_full[, taxonomy_cols]\ncounts &lt;- counts_full[, !names(counts_full) %in% taxonomy_cols]\nrownames(counts) &lt;- taxonomy$BactID\n\n\n\nPrepare Metadata\n\n# Set Group factor with Tumor as reference\nmetadata$Group &lt;- factor(metadata$Group, levels=c(\"Tumor\", \"NAT\"))\nmetadata$Center &lt;- factor(metadata$Center)\n\n# Verify alignment\nif (!identical(colnames(counts), rownames(metadata))) {\n  stop(\"ERROR: Sample order doesn't match!\")\n}\n\nWe use tumor as reference when comparing NAT vs T\n\n\nCreating DESeq2 object\n\ndds &lt;- DESeqDataSetFromMatrix(\n  countData = counts,\n  colData = metadata,\n  design = ~ Center + Group\n)\n\nThis design adjusts for Center effect before testing Group effect\n\n\nEstimate Size factors\n\ndds &lt;- estimateSizeFactors(dds, type=\"poscounts\")\n\nPoscounts works with sparse data and the deseq’s default method - geometric mean fails with it. poscounts uses modified geometric mean that handles zeros in microbome data.\n\n\nRun DESEQ\n\ndds &lt;- DESeq(dds)\n\nThis performs\n\nSize factor normalization\nDispersion estimation (gene-wise, then shrinkage)\nNegative binomial GLM fitting\nWald test for significance\n\n\n\nExtract Results\n\nres &lt;- results(dds, contrast=c(\"Group\", \"NAT\", \"Tumor\"))\n\n\nFormat: c(\"variable\", \"numerator\", \"denominator\")\n\n\n\nc(\"Group\", \"NAT\", \"Tumor\") = NAT vs Tumor\n\n\n\nlog2FC &gt; 0 = higher in NAT\n\n\n\nlog2FC &lt; 0 = higher in Tumor\n\n\n\nProcess results\n\nresults_df &lt;- as.data.frame(res)\nresults_df$BactID &lt;- rownames(results_df)\nresults_final &lt;- merge(results_df, taxonomy, by=\"BactID\")\nresults_final &lt;- results_final[order(results_final$pvalue), ]\n\n\n# All results\nwrite.csv(results_final, \"deseq2_results.csv\", row.names=FALSE)\n\n# Significant only\nsig_005 &lt;- results_final[results_final$padj &lt; 0.05 & !is.na(results_final$padj), ]\nsig_010 &lt;- results_final[results_final$padj &lt; 0.1 & !is.na(results_final$padj), ]\n\nif (nrow(sig_005) &gt; 0) {\n  write.csv(sig_005, \"deseq2_significant_padj005.csv\", row.names=FALSE)\n}\nif (nrow(sig_010) &gt; 0) {\n  write.csv(sig_010, \"deseq2_significant_padj010.csv\", row.names=FALSE)\n}\n\n\n\n\nUnderstanding output\n\nbaseMean\nMean normalized count across all samples.\n→ Higher values indicate more abundant bacteria.\nlog2FoldChange\nLog₂ fold change (NAT vs Tumor).\n→ Positive = enriched in NAT\n→ Negative = enriched in Tumor\n→ |2| = doubling/halving\nlfcSE\nStandard error of the log₂ fold change.\n→ Smaller values mean a more precise estimate.\nstat\nWald test statistic.\n→ Calculated as log2FoldChange / lfcSE\n→ Larger magnitude = stronger evidence for differential abundance.\npvalue\nRaw p-value.\n→ Values &lt; 0.05 are typically considered significant.\npadj\nBenjamini-Hochberg (BH) adjusted p-value.\n→ &lt; 0.05 = significant after correcting for multiple testing\n\n\n3.3.03 MaAsLin2\nIn MaAsLin , we can handle the patient pairing using random effect. MaAsLin uses a linear mixed model framework which can adjust for both the covariates and paired patient issue. This package used relative abudnance count.",
    "crumbs": [
      "Differential Abundance anaysis"
    ]
  },
  {
    "objectID": "index.html#statistical-framework",
    "href": "index.html#statistical-framework",
    "title": "Differential Abundance anaysis",
    "section": "Statistical Framework",
    "text": "Statistical Framework\nMaAsLin2 fits a linear mixed model for each species:\n\\[\n\\log(\\text{abundance}_{ij}) = \\beta_0 + \\beta_{\\text{Center}} + \\beta_{\\text{Group}} + u_{\\text{patient}} + \\varepsilon\n\\]\nwhere:\n\n\\(\\beta_0\\), \\(\\beta_{\\text{Center}}\\), \\(\\beta_{\\text{Group}}\\): fixed effects (including Center and Group/Tumor status)\n\\(u_{\\text{patient}}\\): random effect for patient-specific variation (accounts for pairing)\n\\(\\varepsilon\\): residual error\n\n\nMisc: Fixed effect and Random effect\nFixed effects are These are the systematic variables the ones whose specific effects you want to estimate or test.\nIn the above formula, Center controls for batch effects or site differences.\n\nExample question: Do samples from different hospitals show systematic differences in abundance due to lab or sequencing variation?\nGroup Tests the biological contrast of interest (Tumor vs NAT).\nExample question: Is this bacterium more abundant in tumor tissue than in NAT tissue?\n\nSo, fixed effects represent predictors with consistent, reproducible influence across your dataset — they’re not random noise; they’re what you actually want to measure\nRandom effects accounts for random variability that you don’t want to test directly but must control for, especially in paired or repeated-measures designs\nThis is because conceptually , each patient contribute two samples as they are paired designs (NAT + T). Now obviously, these two tissue samples from the same patient would be more similar to each other than to other patients samples. This similarity violtaes the assumption of independent samples.\nSo, models like MaAsLin adds a random intercept per patient which means that every patient now has their own baseline abundance level. The model doesn’t care which patient has which intercept ,it only cares about the variance among patients (σ²_patient). This “absorbs” the within-patient correlation, preventing it from inflating your fixed-effect estimates.\n\nLoad data\n\nlibrary(Maaslin2)\n\nmetadata &lt;- read.csv(\"DA_metadata.csv\", row.names=1, check.names=FALSE)\ncounts_full &lt;- read.csv(\"DA_counts_relative.csv\", check.names=FALSE)\n\n# Separate taxonomy\ntaxonomy_cols &lt;- c(\"Prevalence in DNA extraction/NTC negative controls\",\n                   \"Prevalence in Paraf. Controls\",\n                   \"BactID\", \"domain\", \"phylum\", \"class\", \"order\", \n                   \"family\", \"genus\", \"species\")\ntaxonomy &lt;- counts_full[, taxonomy_cols]\ncounts &lt;- counts_full[, !names(counts_full) %in% taxonomy_cols]\nrownames(counts) &lt;- taxonomy$BactID\n\n\n\nPrepare Metadata\n\nmetadata$Group &lt;- factor(metadata$Group, levels=c(\"Tumor\", \"NAT\"))\nmetadata$Center &lt;- factor(metadata$Center)\nmetadata$Patient_ID &lt;- factor(metadata$Patient_ID)\n\n\n\nTranspose Data\n\n# MaAsLin2 needs: rows=samples, columns=taxa\ncounts_transposed &lt;- as.data.frame(t(counts))\n\n# Verify alignment\ncat(sprintf(\"Sample alignment check: %s\\n\", \n            ifelse(all(rownames(counts_transposed) == rownames(metadata)), \n                   \"✓ OK\", \"✗ FAILED\")))\n\nMaaslin requries samples as rows and features as columns hence we transpose it.\n\n\nRun MaasLin\n\nfit_data &lt;- Maaslin2(\n  input_data = counts_transposed,\n  input_metadata = metadata,\n  output = \"maaslin2_output\",\n  min_abundance = 0.0,\n  min_prevalence = 0.0,\n  min_variance = 0.0,\n  normalization = \"NONE\",          # Already relative abundances\n  transform = \"LOG\",                # Log transformation for linear model\n  analysis_method = \"LM\",           # Linear model\n  max_significance = 0.25,          # Report if qval &lt; 0.25\n  random_effects = c(\"Patient_ID\"), # ← HANDLES PAIRING\n  fixed_effects = c(\"Center\", \"Group\"),\n  correction = \"BH\",                # Benjamini-Hochberg FDR\n  standardize = TRUE,\n  cores = 1,\n  plot_heatmap = TRUE,\n  heatmap_first_n = 50,\n  plot_scatter = TRUE,\n  max_pngs = 10,\n  save_scatter = FALSE,\n  save_models = FALSE,\n  reference = \"Group,Tumor\"         # Tumor as reference\n)\n\nWe put normlization as None because data is already relative abundance so , we dont re-normlaize. We add Patient ID as random effect to account for pairing.\n\n\nExtract Result\n\n# MaAsLin2 outputs results for ALL fixed effects (Group AND Center)\n# Filter to Group only for main results\n\nresults &lt;- read.csv(\"maaslin2_output/all_results.tsv\", sep=\"\\t\")\ngroup_only &lt;- results[results$metadata == \"Group\", ]\nwrite.csv(group_only, \"maaslin2_group_only_results.csv\", row.names=FALSE)\n\n# Significant only\nsig_results &lt;- read.csv(\"maaslin2_output/significant_results.tsv\", sep=\"\\t\")\nsig_group_only &lt;- sig_results[sig_results$metadata == \"Group\", ]\nwrite.csv(sig_group_only, \"maaslin2_group_significant.csv\", row.names=FALSE)\n\nAs fixed effect it output for both center and group effect. Since we are only focused on group effect that is NAT vs T , we filter it.\n\n\nUnderstanding output\n\nfeature | Bacterial taxon (BactID) | Which bacteria\nmetadata | Variable tested | “Group” or “Center”\nvalue | Specific level being compared | “NAT” (vs reference “Tumor”)\ncoef | Effect size (coefficient) | How much higher/lower in NAT vs Tumor\nstderr | Standard error | Uncertainty of estimate\npval | P-value | Statistical significance\nqval | FDR-adjusted q-value | Multiple testing corrected\nN | Sample size | Number of samples in analysis\nN.not.0 | Non-zero samples | How many samples had this bacteria\n\n\n\n3.3.03 ALDEx2\nALDEx2 is used to identify differentially abundant bacteria while explicitly addressing the compositionality problem in sequencing data.\n\nThe compositionality problem\nBecause sequencing provides relative, not absolute, abundances, all taxa are constrained to sum to one. A change in one taxon therefore alters the proportions of others, creating a compositionality problem that traditional statistical models cannot handle properly.\nTo address this, ALDEx2 models the observed count data as one possible realization of a Dirichlet–multinomial distribution and performs Monte Carlo sampling to account for technical uncertainty. For each sample, it generates multiple simulated instances (typically 128), each representing a plausible composition of counts. Each simulated instance is then transformed using the centered log-ratio (CLR) transformation:\nThe centered log-ratio (CLR) transformation is defined as:\n\\[\n\\mathrm{CLR}(x_i) = \\log \\left( \\frac{x_i}{\\text{geometric mean of all } x_i} \\right )\n\\]\nThis transformation removes the unit-sum constraint and allows meaningful comparison of taxa across samples.\nALDEx2 then performs statistical testing on each Monte Carlo instance usually Welch’s t-test for two-group comparisons such as Tumor vs NAT and computes corresponding effect sizes. These results are averaged across all instances to produce robust estimates of fold change and significance that incorporate sequencing uncertainty.\nWhen covariates (e.g., Center) need to be included, ALDEx2 uses a generalized linear model of the form.\nThe CLR-transformed abundance is modeled as:\n\\[\n\\mathrm{CLR}(\\text{abundance}) = \\beta_0 + \\beta_{\\text{Center}} + \\beta_{\\text{Group}}\n\\]\nfitted separately to each Monte Carlo instance, with coefficients averaged afterward.\nInput data must be integer count matrices (features × samples), not relative abundances, because the Dirichlet-multinomial model requires count-like data. ALDEx2 therefore typically uses files such as DA_counts_integer.csv and DA_metadata.csv.\n\n\nLoad Data\n\nlibrary(ALDEx2)\n\nmetadata &lt;- read.csv(\"DA_metadata.csv\", row.names=1, check.names=FALSE)\ncounts_full &lt;- read.csv(\"DA_counts_integer.csv\", check.names=FALSE)\n\n# Separate taxonomy\ntaxonomy_cols &lt;- c(\"Prevalence in DNA extraction/NTC negative controls\",\n                   \"Prevalence in Paraf. Controls\",\n                   \"BactID\", \"domain\", \"phylum\", \"class\", \"order\", \n                   \"family\", \"genus\", \"species\")\ntaxonomy &lt;- counts_full[, taxonomy_cols]\ncounts &lt;- counts_full[, !names(counts_full) %in% taxonomy_cols]\nrownames(counts) &lt;- taxonomy$BactID\n\n\n\nPrepare Metadata\n\nmetadata$Group &lt;- factor(metadata$Group, levels=c(\"Tumor\", \"NAT\"))\nmetadata$Center &lt;- factor(metadata$Center)\n\n# Verify alignment\nif (!identical(colnames(counts), rownames(metadata))) {\n  stop(\"ERROR: Sample order doesn't match!\")\n}\n\n\n\nCreate Model Matrix(for GLM with Center adjustment)\n\nmm &lt;- model.matrix(~ Center + Group, data = metadata)\n\nThis converts factors into numeric design matrix used for GLM regression.\n\n\nRun Aldex\n\naldex_clr &lt;- aldex.clr(counts, mm, mc.samples=128, denom=\"all\")\n\n\ncounts = integer count matrix\n\n\n\nmm = model matrix (for GLM)\n\n\n\nmc.samples=128 = number of Monte Carlo instances\ndenom=\"all\" = use geometric mean of all features for CLR\n\nWhat the code does:\n\nFor each sample, draws 128 Dirichlet replicates (each sums to 1)\nApplies CLR transformation to each replicate\nResult: 128 CLR-transformed versions of each feature per sample\n\n\n\nRun GLM (adjust for center)\n\naldex_glm &lt;- aldex.glm(aldex_clr, mm)\n\n\nFor each MC instance, fits GLM: CLR ~ Center + Group\nExtracts coefficients for Group effect\nAverages coefficients across 128 instances\nTests if Group coefficient significantly different from 0\n\n\n\nExtract Result\n\naldex_results &lt;- data.frame(aldex_glm)\naldex_results$BactID &lt;- rownames(aldex_results)\n\n# Extract Group effect columns\n# Column names: \"GroupNAT.Est\", \"GroupNAT.pval\", \"GroupNAT.pval.padj\"\naldex_results$coef_Group_adjusted &lt;- aldex_results$GroupNAT.Est\naldex_results$pval_Group &lt;- aldex_results$GroupNAT.pval\naldex_results$padj_Group &lt;- aldex_results$GroupNAT.pval.padj\n\n\n\nMerge with taxonomy and save\n\naldex_results_tax &lt;- merge(aldex_results, taxonomy, by=\"BactID\")\naldex_results_tax &lt;- aldex_results_tax[order(aldex_results_tax$padj_Group), ]\n\nwrite.csv(aldex_results_tax, \"aldex2_glm_results.csv\", row.names=FALSE)\n\n# Significant results\nsig_005 &lt;- aldex_results_tax[aldex_results_tax$padj_Group &lt; 0.05 & \n                              !is.na(aldex_results_tax$padj_Group), ]\nsig_010 &lt;- aldex_results_tax[aldex_results_tax$padj_Group &lt; 0.1 & \n                              !is.na(aldex_results_tax$padj_Group), ]\n\nif (nrow(sig_005) &gt; 0) {\n  write.csv(sig_005, \"aldex2_glm_significant_padj005.csv\", row.names=FALSE)\n}\nif (nrow(sig_010) &gt; 0) {\n  write.csv(sig_010, \"aldex2_glm_significant_padj010.csv\", row.names=FALSE)\n}\n\n\n\nUnderstanding output\n\nGroupNAT.Est | GLM coefficient for Group | Center-adjusted log-ratio difference (NAT vs Tumor)\nGroupNAT.SE | Standard error | Uncertainty of coefficient\nGroupNAT.t.val | T-statistic | coef / SE\nGroupNAT.pval | P-value | Significance of Group effect\nGroupNAT.pval.padj | Adjusted p-value | FDR-corrected\n\n\nInterpretation example:\nGroupNAT.Est = 1.2 GroupNAT.pval.padj = 0.003\nInterpretation: - After adjusting for Center - After averaging across 128 Monte Carlo instances - This bacterium has 1.2 units higher CLR-transformed abundance in NAT vs Tumor - Highly significant (padj &lt; 0.05) - Positive = enriched in NAT - Negative = enriched in Tumor\n\n\n\n3.3.04 ANCOM BC2\nANCOM-BC2 identifies differentially abundant bacteria through a bias-corrected log-linear modeling framework that accounts for both compositional effects and technical biases common in sequencing data. It improves on earlier methods like ANCOM by explicitly estimating and correcting for two major sources of bias sampling fraction bias and taxon-specific efficiency bias making it generally more powerful than ANCOM and less conservative than ALDEx2. ANCOM-BC2 can include covariates such as sequencing center but cannot handle random effects or paired designs.\nThe first bias, sample-level bias (or sampling-fraction bias), arises because different samples capture different total fractions of the microbial community. Even if relative proportions between taxa remain constant, differences in DNA extraction efficiency or sequencing depth mean some samples contain far more total reads than others. ANCOM-BC2 corrects this by estimating a sample-specific normalization factor, δᵢ, that adjusts each sample’s counts to a common scale.\nThe second bias, taxon-level bias, reflects the fact that some bacterial taxa are inherently harder to detect due to biological or technical properties for example, variation in cell wall lysis, GC content, or primer compatibility. These systematic detection differences are modeled through a taxon-specific bias term, νⱼ, which adjusts for consistent over- or under-representation across samples.\nMathematically, the observed count for taxon j in sample i can be expressed as\n\\[\ny_{ij} = \\mathrm{true\\_abundance}_{ij} \\times \\delta_i \\times \\nu_j\n\\]\nANCOM-BC2 estimates both bias terms (\\(\\delta_i\\) and \\(\\nu_j\\)) and removes them to recover bias-corrected abundances:\n\\[\n\\log(\\mathrm{corrected\\_abundance}_{ij}) = \\log(y_{ij}) - \\log(\\delta_i) - \\log(\\nu_j)\n\\]\nA bias-corrected log-linear model is then fitted to these corrected abundances:\n\\[\n\\log(\\mathrm{corrected\\_abundance}) = \\beta_0 + \\beta_{\\text{Center}} + \\beta_{\\text{Group}}\n\\]\nHere, \\(\\beta_{\\text{Group}}\\) represents the estimated log fold-change between groups (e.g., Tumor vs NAT) after removing both sampling and taxon-specific biases.\nThe resulting lfc value provides a bias-adjusted measure of differential abundance, and statistical significance is assessed on this corrected scale.\nFor input, ANCOM-BC2 requires integer count data with features (taxa) as rows and samples as columns, alongside a metadata data frame describing sample covariates. The standard input files are DA_counts_integer.csv and DA_metadata.csv.\n\nLoad Data\n\nlibrary(ANCOMBC)\n\nmetadata &lt;- read.csv(\"DA_metadata.csv\", row.names=1, check.names=FALSE)\ncounts_full &lt;- read.csv(\"DA_counts_integer.csv\", check.names=FALSE)\n\n# Separate taxonomy\ntaxonomy_cols &lt;- c(\"Prevalence in DNA extraction/NTC negative controls\",\n                   \"Prevalence in Paraf. Controls\",\n                   \"BactID\", \"domain\", \"phylum\", \"class\", \"order\", \n                   \"family\", \"genus\", \"species\")\ntaxonomy &lt;- counts_full[, taxonomy_cols]\ncounts &lt;- counts_full[, !names(counts_full) %in% taxonomy_cols]\nrownames(counts) &lt;- taxonomy$BactID\n\n\n\nPrepare Metadata\n\nmetadata$Group &lt;- factor(metadata$Group, levels=c(\"Tumor\", \"NAT\"))\nmetadata$Center &lt;- factor(metadata$Center)\n\n# Verify alignment\nif (!identical(colnames(counts), rownames(metadata))) {\n  stop(\"ERROR: Sample order doesn't match!\")\n}\n\n\n\nRun ANCOM\n\nancombc2_result &lt;- ancombc2(\n  data = counts,\n  assay_name = NULL,\n  tax_level = NULL,\n  fix_formula = \"Group + Center\",    # Fixed effects\n  rand_formula = NULL,                # No random effects\n  p_adj_method = \"BH\",                # Benjamini-Hochberg\n  pseudo_sens = TRUE,                 # Sensitivity analysis\n  prv_cut = 0,                        # No prevalence filter (already done)\n  lib_cut = 0,                        # No library size filter\n  s0_perc = 0.05,                     # Small constant for stability\n  group = \"Group\",                    # Primary variable\n  struc_zero = FALSE,                 # No structural zeros\n  neg_lb = FALSE,                     # No negative lower bound\n  alpha = 0.05,                       # Significance threshold\n  n_cl = 1,                           # Number of cores\n  verbose = TRUE,\n  global = FALSE,                     # No global test\n  pairwise = FALSE,                   # No pairwise (only 2 groups)\n  dunnet = FALSE,                     # No Dunnett test\n  trend = FALSE,                      # No trend test\n  iter_control = list(tol = 1e-2, max_iter = 20, verbose = FALSE),\n  em_control = list(tol = 1e-5, max_iter = 100),\n  lme_control = NULL,\n  mdfdr_control = NULL,\n  trend_control = NULL,\n  meta_data = metadata\n)\n\n\n\nExtract Result\n\nresults_df &lt;- ancombc2_result$res\n\n# Rename taxon to BactID for merging\nresults_df$BactID &lt;- results_df$taxon\n\n# Merge with taxonomy\nresults_tax &lt;- merge(results_df, taxonomy, by=\"BactID\", all.x=TRUE)\n\n# Sort by q-value\nresults_tax &lt;- results_tax[order(results_tax$q_GroupNAT), ]\n\n\n\nGet sigificant results\n\n# By q-value thresholds\nsig_005 &lt;- results_tax[results_tax$q_GroupNAT &lt; 0.05 & \n                       !is.na(results_tax$q_GroupNAT), ]\nsig_010 &lt;- results_tax[results_tax$q_GroupNAT &lt; 0.1 & \n                       !is.na(results_tax$q_GroupNAT), ]\n\n# By ANCOM-BC2 declaration (accounts for effect size)\nsig_declared &lt;- results_tax[results_tax$diff_GroupNAT == TRUE & \n                            !is.na(results_tax$diff_GroupNAT), ]\n\n# Robust significant (passed sensitivity analysis)\nsig_robust &lt;- results_tax[results_tax$diff_robust_GroupNAT == TRUE & \n                          !is.na(results_tax$diff_robust_GroupNAT), ]\n\n\n\nSave result\n\n# All results\nwrite.csv(results_tax, \"ancombc2_results.csv\", row.names=FALSE)\n\n# Significant by q-value\nif (nrow(sig_005) &gt; 0) {\n  write.csv(sig_005, \"ancombc2_significant_q005.csv\", row.names=FALSE)\n}\nif (nrow(sig_010) &gt; 0) {\n  write.csv(sig_010, \"ancombc2_significant_q010.csv\", row.names=FALSE)\n}\n\n# ANCOM-BC2 declared significant\nif (nrow(sig_declared) &gt; 0) {\n  write.csv(sig_declared, \"ancombc2_significant_declared.csv\", row.names=FALSE)\n}\n\n# Robust significant (most conservative)\nif (nrow(sig_robust) &gt; 0) {\n  write.csv(sig_robust, \"ancombc2_significant_robust.csv\", row.names=FALSE)\n}\n\n\n\nUnderstanding the output file\n\ntaxon | Bacterial taxon | Which bacteria\nlfc_GroupNAT | Log fold change | Bias-corrected difference (NAT vs Tumor)&lt;br&gt;Positive = enriched in NAT\nse_GroupNAT | Standard error | Uncertainty of LFC\nW_GroupNAT | Wald statistic | lfc / se&lt;br&gt;Larger = stronger evidence\np_GroupNAT | P-value | Raw significance\nq_GroupNAT | Q-value | FDR-adjusted (use this for significance)\ndiff_GroupNAT | Logical (TRUE/FALSE) | ANCOM-BC2’s declaration of significance\npassed_ss_GroupNAT | Logical | Passed sample size filter?\ndiff_robust_GroupNAT | Logical | Robust to sensitivity analysis?&lt;br&gt;Most conservative\nAlso includes:\n\nlfc_(Intercept) = baseline (Tumor at reference Center)\nlfc_CenterRambam, lfc_CenterSheba = Center effects (adjustments)\n\nLog Fold Change (lfc):\n\nlfc | Interpretation | Fold Change\n+1 | 2× higher in NAT | 2\n-1 | 2× lower in NAT (2× higher in Tumor) | 0.5\n+2 | 4× higher in NAT | 4\n0 | No difference | 1",
    "crumbs": [
      "Differential Abundance anaysis"
    ]
  }
]